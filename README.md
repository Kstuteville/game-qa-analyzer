# Emotion-Trace-QA
Game QA Analyzer
Emotion-Aware Gameplay Analysis for Scalable Game QA
Computer-visionâ€“driven QA system that analyzes gameplay footage and correlates in-game events with player emotional states, producing structured, timestamped insights without manual video review.

ğŸš€ Overview
Game QA Analyzer automates playtest analysis by combining:

- Computer Vision (what happens on screen)
- Emotion Inference (how players react)
- Temporal Alignment (when and why)

Designed for game studios, QA teams, and researchers working with pre-release or private builds where traditional analytics fall short.

âœ¨ Features

âœ” Gameplay Event Detection â€” YOLOv8-powered object & event recognition
âœ” Emotion Inference â€” Facial expression analysis (FER) with planned audio/physiological expansion
âœ” Timestamped QA Logs â€” Structured eventâ€“emotion correlations
âœ” Custom Fine-Tuning â€” Game-specific models without ML expertise
âœ” Privacy-First â€” Runs entirely on-device (NVIDIA GB10)


ğŸ§  How It Works
1. Gameplay Event Detection

Uses YOLOv8 to identify:
- Enemy encounters
- UI states
- Player deaths/failures
- Items/objectives
- Combat intensity

2. Emotion Inference
Analyzes facecam footage to detect:
- Calm
- Focused
- Frustrated
- Stressed
- Confused

4. Temporal Correlation
Links events to emotional states:
json{
  "time": 42.31,
  "game_event": "player_death", 
  "emotion_state": "frustrated",
  "confidence": 0.81
} 

ğŸ“Š Output

Timestamped JSON logs for QA dashboards
Eventâ€“emotion correlations for UX analysis
Accessibility insights for inclusive design
Emotional pacing data for difficulty tuning


ğŸ”’ Privacy & Security
All training and inference runs locally on NVIDIA GB10:

No gameplay footage uploaded to third parties
Pre-release builds remain secure
NDA-compliant workflow
Studio-controlled data pipeline


ğŸ›  Tech Stack

Python
YOLOv8 (Ultralytics)
OpenCV
FER (Facial Emotion Recognition)
PyTorch
NVIDIA GPU acceleration (GB10)

Planned: NVIDIA VLMs, multimodal fusion (audio + vision), interactive QA debugger

ğŸ§ª Fine-Tuning Workflow
Studios can fine-tune models without ML expertise:
- Record gameplay clips
- Label game-specific events
- Fine-tune YOLOv8 locally on GB10
- Run QA analysis offline

No external APIs. No cloud training. No data leakage.

ğŸ¯ Use Cases
- Faster QA iteration
- Emotion-aware difficulty adjustment (DDA)
- Accessibility testing
- Player frustration modeling
- UX research for unreleased titles


ğŸ“Œ Project Status

- âœ… Core CV pipeline implemented
- âœ… YOLOv8 fine-tuning operational
- âœ… Structured QA logs generated
- ğŸš§ Visual QA debugger (in progress)
- ğŸš§ Multimodal emotion fusion (planned)


ğŸ‘©â€ğŸ’» Author
Kaylie Stuteville
MS Integrated Design & Media â€” NYU Tandon
Focus: AI-driven game systems, emotion-aware NPCs, scalable QA tools

ğŸ”— Why This Matters
Studios log what players do â€” but not how they feel.
Game QA Analyzer bridges quantitative telemetry with qualitative player experience, enabling emotion-driven game design at scale.
